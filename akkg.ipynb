{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd7cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "import gensim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b21e6",
   "metadata": {},
   "source": [
    "### Get text and load as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f4fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/evanwineland/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PART ONE\\nChapter 1\\nHappy families are all al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everything was in confusion in the Oblonskys’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The wife had discovered that the husband was c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This position of affairs had now lasted three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every person in the house felt that there was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence\n",
       "0  PART ONE\\nChapter 1\\nHappy families are all al...\n",
       "1  Everything was in confusion in the Oblonskys’ ...\n",
       "2  The wife had discovered that the husband was c...\n",
       "3  This position of affairs had now lasted three ...\n",
       "4  Every person in the house felt that there was ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get text and load as a DataFrame\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def read_book_to_dataframe(file_path):\n",
    "    # Read the text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(sentences, columns=['Sentence'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Using the .txt file that's in the same directory\n",
    "file_path = 'anna_karenina.txt'\n",
    "df = read_book_to_dataframe(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f256a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: install spacy at the command line first.  Then, download en_core_web_sim\n",
    "import re\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60494f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947ab1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # only analyze if the current token isn't punctuation\n",
    "    if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35eda93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16807,\n",
       "                                                                                                                                                                                                   Sentence\n",
       " 0                                                                                                       PART ONE\\nChapter 1\\nHappy families are all alike; every unhappy family is unhappy in its own way.\n",
       " 1                                                                                                                                                     Everything was in confusion in the Oblonskys’ house.\n",
       " 2  The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on liv...\n",
       " 3                     This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n",
       " 4  Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e904c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unhappy  family', 'own  way']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(df['Sentence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61800de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16807/16807 [01:34<00:00, 178.42it/s]\n"
     ]
    }
   ],
   "source": [
    "e_pairs = []\n",
    "\n",
    "for i in tqdm(df[\"Sentence\"]):\n",
    "    e_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f052ae73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unhappy  family', 'own  way'],\n",
       " ['Everything', 'Oblonskys  house'],\n",
       " ['she', 'same  him'],\n",
       " ['only  husband', 'painfully  it'],\n",
       " ['stray  people', 'common  Oblonskys'],\n",
       " ['own  husband', 'three  days'],\n",
       " ['just kitchen coachman', 'warning'],\n",
       " ['days Stepan Arkadyevitch he', 'covered  study'],\n",
       " ['once  he', 'eyes'],\n",
       " ['now  he', 'dream']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f799b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Matcher class object \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    #define the pattern \n",
    "    pattern = [{'DEP':'ROOT'},\n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "    matcher.add(\"matching_1\", [pattern]) \n",
    "\n",
    "    matches = matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "\n",
    "    span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "    return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186f51ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation(\"Kaan finished the race.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f42fcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16807/16807 [01:36<00:00, 173.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is unhappy',\n",
       " 'was in',\n",
       " 'discovered',\n",
       " 'lasted',\n",
       " 'felt',\n",
       " 'been at',\n",
       " 'walked off',\n",
       " 'woke',\n",
       " 'embraced',\n",
       " 'thought',\n",
       " 'was',\n",
       " 'be sure',\n",
       " 'giving',\n",
       " 'was in',\n",
       " 'remembered',\n",
       " 'twinkled',\n",
       " 'was nice',\n",
       " 'dropped',\n",
       " 'stretched',\n",
       " 'remembered',\n",
       " 'Ah',\n",
       " 'muttered',\n",
       " 'was present',\n",
       " 'forgive',\n",
       " 'is',\n",
       " 'reflected',\n",
       " 'kept',\n",
       " 'was',\n",
       " 'fussing',\n",
       " '’s',\n",
       " 'this',\n",
       " 'was',\n",
       " 'happened to',\n",
       " 'succeed in',\n",
       " 'reflected',\n",
       " 'smile',\n",
       " 'shuddered',\n",
       " 'refused',\n",
       " 'thought',\n",
       " '’s',\n",
       " 'said to',\n",
       " 'was',\n",
       " 'was incapable',\n",
       " 'at',\n",
       " 'was',\n",
       " 'felt',\n",
       " 'managed',\n",
       " 'thought',\n",
       " 'supposed',\n",
       " 'turned']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = [get_relation(i) for i in df[\"Sentence\"]]\n",
    "relations[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f7b0b",
   "metadata": {},
   "source": [
    "### Create and visualize the KG using entities and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b979b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [i[0] for i in e_pairs]\n",
    "target = [i[1] for i in e_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "514d69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unhappy  family</td>\n",
       "      <td>own  way</td>\n",
       "      <td>is unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everything</td>\n",
       "      <td>Oblonskys  house</td>\n",
       "      <td>was in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she</td>\n",
       "      <td>same  him</td>\n",
       "      <td>discovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>only  husband</td>\n",
       "      <td>painfully  it</td>\n",
       "      <td>lasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stray  people</td>\n",
       "      <td>common  Oblonskys</td>\n",
       "      <td>felt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source             target    relation\n",
       "0  unhappy  family           own  way  is unhappy\n",
       "1       Everything   Oblonskys  house      was in\n",
       "2              she          same  him  discovered\n",
       "3    only  husband      painfully  it      lasted\n",
       "4    stray  people  common  Oblonskys        felt"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_df = pd.DataFrame({'source': source, 'target': target, 'relation': relations})\n",
    "kg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e8115fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_pandas_edgelist() got multiple values for argument 'edge_attr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas_edgelist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkg_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_using\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDiGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m      4\u001b[0m pos \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mspring_layout(graph, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/AKToKG/AKKG/lib/python3.9/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "\u001b[0;31mTypeError\u001b[0m: from_pandas_edgelist() got multiple values for argument 'edge_attr'"
     ]
    }
   ],
   "source": [
    "graph = nx.from_pandas_edgelist(kg_df[kg_df['source']==\"Anna\"], \"source\", \"target\", edge_attr = True, create_using=nx.MultiDiGraph())\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "pos = nx.spring_layout(graph, k = 1)\n",
    "nx.draw(graph, with_labels=True, node_color = 'orange', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos, font_weight = 'bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf2a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKKG",
   "language": "python",
   "name": "akkg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
